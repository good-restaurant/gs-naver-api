# 🍽️ 모범음식점 데이터 구축 과정
> 공공데이터와 네이버 API/크롤링을 기반으로 전국 모범음식점 데이터를 정제·보완·통합하는 데이터 구축 과정입니다.

---

## 📖 개요
이 저장소는 **전국 모범음식점 데이터의 구축 과정**을 기록하고 관리하기 위한 공간입니다.  
원본 공공데이터를 정제하고, 네이버 API 및 크롤링을 통해 보완 데이터를 수집하여  
최종적으로 **지도 서비스 및 공간정보 플랫폼**에서 활용 가능한 형태로 가공합니다.

---


## 1️⃣ 데이터 전처리 (`01_preprocess.py`)
> 원본 엑셀(`모범음식점_리스트_지오코딩_4326.xlsx`)을 정제하여 `restaurant_clean.csv`로 저장합니다.
- 중복 제거 (`업소명 + 주소`)
- 결측치 보완 (`category ← menu`)
- 전화번호 표준화 (`지역번호 규칙`)
- 행정구역 자동 분리 (`ctp_kor_nm`, `sig_kor_nm`)

📄 [자세히 보기](src/01_preprocess.py)

---

## 2️⃣ 네이버 API 연동 (`02_naver_api_fetch.py`)
> 네이버 Local API를 사용해 `restaurant_name + address`로 검색 후,  
> `category`, `telephone`, `link`, `mapx`, `mapy` 정보를 매칭합니다.

- API 호출 속도 조절 (`time.sleep(0.2)`)
- 카테고리 자동 분리 (`대분류 / 소분류`)
- 결과 엑셀(`output.xlsx`) 저장

📄 [자세히 보기](src/02_naver_api_fetch.py)

---

## 3️⃣ 네이버 플레이스 크롤링 (`03_place_crawling.py`)
> Selenium을 이용하여 네이버 플레이스의 `ID`를 수집합니다.

- `place_id` 크롤링
- `iframe` 전환 및 동적 요소 대기

📄 [자세히 보기](src/03_place_crawling.py)

---

## 4️⃣ 네이버 메뉴·가격 크롤링 (`04_menu_crawling.py`)
> Selenium을 이용하여 네이버 플레이스의 메뉴명과 가격을 수집합니다

- 텍스트 기반 메뉴 섹션 파싱
    - h2 섹션 헤더의 '메뉴' 텍스트와 ul/li 구조를 기준으로 Xpath 선택
    - 가격 문자열에서 숫자만 추출하여 price_num(정수, KRW) 생성

- 메뉴판 이미지 전용 감지
    - '메뉴판 이미지로 보기' 요소 존재 시 텍스트 수집 불가로 판단, note에 사유 기록

📄 [자세히 보기](src/04_menu_crawling.py)

---

## 5️⃣ 메뉴·가격 전처리 (05_menu_preprocess.py)
> 크롤링된 menu 텍스트에서 메뉴명/가격을 자동 분리하고 csv로 저장합니다.

- 메뉴 문자열에서 가격 패턴 자동 식별
    - \d+,?\d+원, ₩숫자, 숫자원 등 다양한 가격 포맷 지원

- 메뉴명에서 가격 제거 후 클린 텍스트 생성
- 가격에서 숫자만 추출하여 정수 형태로 저장
- 메뉴명이 255자를 초과하면 자동 제외

📄 [자세히 보기](src/05_menu_preprocess.py)
