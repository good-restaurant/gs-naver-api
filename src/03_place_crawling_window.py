# ===== 1ï¸âƒ£ í™˜ê²½ ì„¸íŒ… (Windows ì „ìš©) =====
import pandas as pd
import re
import time
from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.common.keys import Keys
from selenium.webdriver.chrome.service import Service
from selenium.webdriver.chrome.options import Options
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from webdriver_manager.chrome import ChromeDriverManager

# Chrome ìë™ ê²½ë¡œ ê´€ë¦¬
chrome_service = Service(ChromeDriverManager().install())
chrome_options = Options()
chrome_options.add_argument("--no-sandbox")
chrome_options.add_argument("--disable-dev-shm-usage")
chrome_options.add_argument("--start-maximized")
chrome_options.add_argument("--lang=ko-KR")
chrome_options.add_argument(
    "user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) "
    "AppleWebKit/537.36 (KHTML, like Gecko) "
    "Chrome/120.0.0.0 Safari/537.36"
)

# â€» headless ëª¨ë“œëŠ” ê°œë°œ ì¤‘ ë¹„í™œì„±í™” ê¶Œì¥
# chrome_options.add_argument("--headless=new")

driver = webdriver.Chrome(service=chrome_service, options=chrome_options)
wait = WebDriverWait(driver, 15)
print("âœ… ChromeDriver ì‹¤í–‰ ì™„ë£Œ")


# ===== 2ï¸âƒ£ ê³µí†µ í•¨ìˆ˜ =====
def switch_left():
    """ì™¼ìª½ ê²€ìƒ‰ê²°ê³¼ iframe ì „í™˜"""
    driver.switch_to.default_content()
    wait.until(EC.frame_to_be_available_and_switch_to_it((By.ID, "searchIframe")))


def switch_right():
    """ì˜¤ë¥¸ìª½ ìƒì„¸ì •ë³´ iframe ì „í™˜"""
    driver.switch_to.default_content()
    wait.until(EC.frame_to_be_available_and_switch_to_it((By.ID, "entryIframe")))


# ===== 3ï¸âƒ£ Place ID í¬ë¡¤ëŸ¬ =====
def crawl_place_id(name, sig, emd):
    query = name if ("ì " in name and "ë°˜ì " not in name) else f"{name} {sig} {emd}"
    print(f"ğŸ” ê²€ìƒ‰ ì¤‘: {query}")

    result = {
        "restaurant_name": name,
        "sig_kor_nm": sig,
        "emd_kor_nm": emd,
        "place_id": None,
    }

    try:
        driver.get("https://map.naver.com/v5/search/" + query)
        time.sleep(2.5)

        # âœ… CASE 1: ê²€ìƒ‰ ê²°ê³¼ ë¦¬ìŠ¤íŠ¸ ì¡´ì¬ ì‹œ ì²« í•­ëª© í´ë¦­
        try:
            switch_left()
            items = driver.find_elements(By.XPATH, '//*[@id="_pcmap_list_scroll_container"]/ul/li')
            if items:
                items[0].find_element(By.TAG_NAME, "a").send_keys(Keys.ENTER)
                switch_right()
        except:
            # âœ… CASE 2: ë°”ë¡œ ìƒì„¸ í˜ì´ì§€ ì§„ì…
            switch_right()

        # ğŸ”¹ URLì—ì„œ place_id ì¶”ì¶œ
        current_url = driver.current_url
        match = re.search(r"place/(\d+)", current_url)
        if match:
            result["place_id"] = match.group(1)

        print(f"âœ… ì™„ë£Œ: {name} (placeId={result['place_id']})")

    except Exception as e:
        print(f"âš ï¸ ì˜ˆì™¸ ë°œìƒ: {e}")

    return result


# ===== 4ï¸âƒ£ ì‹¤í–‰ ë° ì €ì¥ =====
file_path = r"C:\All4land_Project\good_restaurant_temp.csv"  # âœ… ë¡œì»¬ íŒŒì¼ ê²½ë¡œ
df = pd.read_csv(file_path, encoding="utf-8")
print(f"ğŸ“„ ì´ {len(df)}ê°œ ë°ì´í„° ë¡œë“œ ì™„ë£Œ")

results = []
for i, row in df.iterrows():
    res = crawl_place_id(row["restaurant_name"], row["sig_kor_nm"], row["emd_kor_nm"])
    results.append(res)

output = pd.DataFrame(results)
output_path = r"C:\All4land_Project\good_restaurant_placeid.csv"
output.to_csv(output_path, index=False, encoding="utf-8-sig")

print(f"ğŸ‰ í¬ë¡¤ë§ ì™„ë£Œ â†’ {output_path} ì €ì¥ ì™„ë£Œ")
driver.quit()
